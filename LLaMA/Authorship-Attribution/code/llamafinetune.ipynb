{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import transformers\n",
    "from datasets import load_dataset\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    get_peft_model_state_dict,\n",
    "    prepare_model_for_int8_training,\n",
    "    set_peft_model_state_dict,\n",
    "    PeftType,\n",
    "    TaskType,\n",
    "    PeftModelForSequenceClassification\n",
    ")\n",
    "from transformers import LlamaTokenizer ,LlamaForSequenceClassification ,LlamaForCausalLM,Trainer,TrainingArguments\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "base_model = \"../ljcllama-7b-hf\"\n",
    "device_map = \"auto\"\n",
    "num_epochs = 20\n",
    "lr = 5e-5\n",
    "peft_type = PeftType.LORA\n",
    "datasets = load_dataset(\"csv\", data_files={\"train\":\"train.csv\",\"test\":\"valid.csv\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = LlamaForSequenceClassification.from_pretrained(\n",
    "        base_model,\n",
    "        load_in_8bit = True,\n",
    "        torch_dtype = torch.float16,\n",
    "        num_labels = 66,\n",
    "        device_map = device_map\n",
    "    )\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(base_model)\n",
    "tokenizer.pad_token = -100\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "        metirc = evaluate.load(\"accuracy\")\n",
    "        logits , labels = eval_pred\n",
    "        predictions = np.argmax(logits,axis=-1)\n",
    "        return metirc.compute(predictions=predictions,references=labels)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"],padding = \"max_length\",truncation = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_int8_training(model)\n",
    "\n",
    "config = LoraConfig(\n",
    "        r=8,\n",
    "        lora_alpha=16,\n",
    "        inference_mode=False,\n",
    "        lora_dropout=0.1,\n",
    "        target_modules =  [\n",
    "        \"q_proj\",\n",
    "        \"v_proj\",\n",
    "    ],\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    "    )\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "model.model.score = model.model.score.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.print_trainable_parameters()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = datasets.map(tokenize_function,batched=True)\n",
    "small_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42)\n",
    "small_eval_dataset = tokenized_dataset[\"test\"].shuffle(seed=42)\n",
    "train_args = TrainingArguments(logging_strategy=\"steps\",logging_steps=1,fp16=True,per_device_train_batch_size=2,eval_steps=10,evaluation_strategy=\"steps\",per_device_eval_batch_size=1,num_train_epochs=num_epochs,learning_rate=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model = model,args = train_args,train_dataset=small_train_dataset,eval_dataset=small_eval_dataset,compute_metrics=compute_metrics)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"llama-for-attack-ada\")\n",
    "evaldataset = tokenized_dataset['test'].remove_columns('text').rename_column('label','labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def col_fn(examples):\n",
    "    return tokenizer.pad(examples,padding=\"max_length\",return_tensors=\"pt\")\n",
    "evaldataset = DataLoader(evaldataset,collate_fn=col_fn,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch.functional import F\n",
    "count = 0\n",
    "model.eval()\n",
    "#model.to(device)\n",
    "for step,batch in enumerate(tqdm(evaldataset)):\n",
    "    batch.to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(**batch)\n",
    "    count += int(batch['labels']== torch.argmax(F.softmax(output.logits,dim=1),dim=1))\n",
    "print(count/len(evaldataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"ljc-llama-for-attack-adaption\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model  = LlamaForSequenceClassification.from_pretrained(\"ljcllama-7b-hf\",num_labels = 66,return_dict=True,device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PeftModelForSequenceClassification.from_pretrained(model,\"ljcoutputdir\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
