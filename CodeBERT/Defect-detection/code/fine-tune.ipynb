{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "fine-tune CodeBERT\n",
    "Author: Liu Jin Cheng\n",
    "'''\n",
    "from transformers import RobertaForSequenceClassification,RobertaTokenizer,get_linear_schedule_with_warmup\n",
    "from datasets import load_dataset,Dataset\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import evaluate\n",
    "import torch\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from torch.functional import F\n",
    "from torch.cuda.amp import autocast as autocast,GradScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "data_path = os.path.join(\"..\",\"preprocess\",\"dataset\")\n",
    "train_batch_size = 8\n",
    "eval_batch_size = 8\n",
    "lr = 5e-5\n",
    "num_epochs = 30\n",
    "model_name = \"microsoft/codebert-base\"\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_name)\n",
    "model = RobertaForSequenceClassification.from_pretrained(model_name,num_labels = 66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_metrics(eval_pred):\n",
    "        metirc = evaluate.load(\"accuracy\")\n",
    "        logits , labels = eval_pred\n",
    "        predictions = np.argmax(logits,axis=-1)\n",
    "        return metirc.compute(predictions=predictions,references=labels)\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "        return tokenizer(examples[\"text\"],truncation = True,padding=True) \n",
    "\n",
    "def collate_fn(examples):\n",
    "    return tokenizer.pad(examples, padding=\"max_length\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = pd.read_pickle(os.path.join(data_path,\"train.pkl\"))\n",
    "dfvalid = pd.read_pickle(os.path.join(data_path,\"valid.pkl\"))\n",
    "traindatasets = Dataset.from_pandas(dftrain)\n",
    "validdatasets = Dataset.from_pandas(dfvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=66, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized_dataset = traindatasets.map(tokenize_function,batched=True,remove_columns=[\"text\",\"__index_level_0__\"]).rename_column(\"label\",\"labels\")\n",
    "valid_tokenized_dataset = validdatasets.map(tokenize_function,batched=True,remove_columns=[\"text\",\"__index_level_0__\"]).rename_column(\"label\",\"labels\")\n",
    "train_dataloader = DataLoader(train_tokenized_dataset,shuffle=True,collate_fn=collate_fn,batch_size = train_batch_size)\n",
    "eval_dataloader = DataLoader(valid_tokenized_dataset , collate_fn=collate_fn,batch_size = eval_batch_size)\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(params=model.parameters(), lr=lr)\n",
    "\n",
    "# Instantiate scheduler\n",
    "\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0.06 * (len(train_dataloader) * num_epochs),\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 200/2732 [01:20<16:56,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 199 loss tensor(1.0105, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 400/2732 [02:39<15:45,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 399 loss tensor(0.8993, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 600/2732 [03:58<14:22,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 599 loss tensor(0.6769, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 799/2732 [05:16<12:38,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 799 loss tensor(0.4618, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:47<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 step 799 acc  0.568814055636896\n",
      "Update Max eval acc 0.568814055636896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1000/2732 [07:34<10:51,  2.66it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 999 loss tensor(0.3564, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1200/2732 [08:48<09:36,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 1199 loss tensor(0.2870, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 1401/2732 [09:44<04:11,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 1399 loss tensor(0.2456, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1599/2732 [10:21<03:32,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 1599 loss tensor(0.2483, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:22<00:00, 15.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 step 1599 acc  0.58199121522694\n",
      "Update Max eval acc 0.58199121522694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1801/2732 [11:34<02:54,  5.34it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 1799 loss tensor(0.2169, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2001/2732 [12:11<02:17,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 1999 loss tensor(0.1885, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2201/2732 [12:49<01:39,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 2199 loss tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2399/2732 [13:26<01:01,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 2399 loss tensor(0.1763, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:22<00:00, 15.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  0 step 2399 acc  0.5904099560761347\n",
      "Update Max eval acc 0.5904099560761347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2601/2732 [14:39<00:24,  5.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 2599 loss tensor(0.2065, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2732/2732 [15:03<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 step 2731 trainLoss: 0.052859855352834106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 201/2732 [00:37<07:56,  5.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 199 loss tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 401/2732 [01:15<07:17,  5.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 399 loss tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 601/2732 [01:52<06:41,  5.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 599 loss tensor(0.1791, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 799/2732 [02:29<06:00,  5.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 799 loss tensor(0.1707, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:22<00:00, 15.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 step 799 acc  0.6255490483162518\n",
      "Update Max eval acc 0.6255490483162518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1001/2732 [03:42<05:25,  5.32it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 999 loss tensor(0.1679, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1201/2732 [04:19<04:49,  5.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 1199 loss tensor(0.1938, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1400/2732 [05:00<09:01,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 1399 loss tensor(0.1751, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1599/2732 [06:18<07:27,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 1599 loss tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:47<00:00,  7.25it/s]\n",
      " 59%|█████▊    | 1600/2732 [07:06<4:34:41, 14.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 step 1599 acc  0.6218887262079063\n",
      "Early Stopping record count 1 / 6 Will stop Max eval acc 0.6255490483162518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1800/2732 [08:27<06:23,  2.43it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 1799 loss tensor(0.1932, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2000/2732 [09:47<04:55,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 1999 loss tensor(0.2077, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2200/2732 [11:06<03:35,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 2199 loss tensor(0.1779, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2399/2732 [12:25<02:11,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 2399 loss tensor(0.2260, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:43<00:00,  7.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  1 step 2399 acc  0.6284773060029283\n",
      "Update Max eval acc 0.6284773060029283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2600/2732 [14:35<00:49,  2.68it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 2599 loss tensor(0.1787, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2732/2732 [15:11<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 step 2731 trainLoss: 0.021297891773242573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 200/2732 [01:19<17:02,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 199 loss tensor(0.1684, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 400/2732 [02:38<15:41,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 399 loss tensor(0.1417, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 600/2732 [03:57<14:25,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 599 loss tensor(0.1766, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 799/2732 [05:15<12:41,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 799 loss tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:46<00:00,  7.30it/s]\n",
      " 29%|██▉       | 800/2732 [06:03<7:45:53, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2 step 799 acc  0.5944363103953147\n",
      "Early Stopping record count 1 / 6 Will stop Max eval acc 0.6284773060029283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1000/2732 [07:22<11:42,  2.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 999 loss tensor(0.1734, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1200/2732 [08:35<09:30,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 1199 loss tensor(0.1683, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1400/2732 [09:48<08:19,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 1399 loss tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1599/2732 [10:51<07:28,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 1599 loss tensor(0.2284, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:46<00:00,  7.28it/s]\n",
      " 59%|█████▊    | 1600/2732 [11:38<4:33:28, 14.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2 step 1599 acc  0.626281112737921\n",
      "Early Stopping record count 2 / 6 Will stop Max eval acc 0.6284773060029283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1800/2732 [12:57<06:17,  2.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 1799 loss tensor(0.2461, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2000/2732 [14:17<04:57,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 1999 loss tensor(0.1690, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2200/2732 [15:36<03:35,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 2199 loss tensor(0.1232, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2399/2732 [16:55<02:12,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 2399 loss tensor(0.1406, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:46<00:00,  7.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  2 step 2399 acc  0.6394582723279648\n",
      "Update Max eval acc 0.6394582723279648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2600/2732 [19:08<00:49,  2.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 2599 loss tensor(0.1291, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2732/2732 [19:56<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 step 2731 trainLoss: 0.01986309742291852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 200/2732 [01:03<17:03,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 199 loss tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 400/2732 [02:23<15:42,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 399 loss tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 600/2732 [03:42<14:18,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 599 loss tensor(0.0801, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 799/2732 [05:01<12:47,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 799 loss tensor(0.1619, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:47<00:00,  7.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3 step 799 acc  0.6636163982430454\n",
      "Update Max eval acc 0.6636163982430454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1000/2732 [07:21<11:39,  2.48it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 999 loss tensor(0.1750, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1200/2732 [08:35<09:33,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 1199 loss tensor(0.1256, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1400/2732 [09:48<08:16,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 1399 loss tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1599/2732 [11:05<07:26,  2.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 1599 loss tensor(0.1603, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:46<00:00,  7.30it/s]\n",
      " 59%|█████▊    | 1600/2732 [11:52<4:33:00, 14.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3 step 1599 acc  0.6606881405563689\n",
      "Early Stopping record count 1 / 6 Will stop Max eval acc 0.6636163982430454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1800/2732 [13:11<06:18,  2.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 1799 loss tensor(0.1494, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2000/2732 [14:31<04:56,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 1999 loss tensor(0.1120, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2200/2732 [15:50<03:33,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 2199 loss tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2399/2732 [17:09<02:12,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 2399 loss tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:45<00:00,  7.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  3 step 2399 acc  0.6676427525622255\n",
      "Update Max eval acc 0.6676427525622255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2600/2732 [19:22<00:49,  2.69it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 2599 loss tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2732/2732 [20:03<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 step 2731 trainLoss: 0.01867215364311016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 200/2732 [01:11<17:10,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 199 loss tensor(0.1154, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 400/2732 [02:30<15:47,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 399 loss tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 600/2732 [03:50<14:26,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 599 loss tensor(0.1474, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 799/2732 [05:09<12:42,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 799 loss tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:46<00:00,  7.29it/s]\n",
      " 29%|██▉       | 800/2732 [05:56<7:46:37, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4 step 799 acc  0.664714494875549\n",
      "Early Stopping record count 1 / 6 Will stop Max eval acc 0.6676427525622255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1000/2732 [07:15<11:42,  2.46it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 999 loss tensor(0.1085, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1200/2732 [08:30<09:33,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 1199 loss tensor(0.0994, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1400/2732 [09:43<08:15,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 1399 loss tensor(0.1951, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1599/2732 [10:59<07:27,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 1599 loss tensor(0.1226, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:46<00:00,  7.29it/s]\n",
      " 59%|█████▊    | 1600/2732 [11:47<4:33:23, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4 step 1599 acc  0.657393850658858\n",
      "Early Stopping record count 2 / 6 Will stop Max eval acc 0.6676427525622255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1800/2732 [13:06<06:18,  2.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 1799 loss tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2000/2732 [14:25<04:56,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 1999 loss tensor(0.1128, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2200/2732 [15:45<03:36,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 2199 loss tensor(0.1222, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2399/2732 [17:04<02:12,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 2399 loss tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:47<00:00,  7.27it/s]\n",
      " 88%|████████▊ | 2400/2732 [17:51<1:20:18, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  4 step 2399 acc  0.6625183016105417\n",
      "Early Stopping record count 3 / 6 Will stop Max eval acc 0.6676427525622255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2600/2732 [19:11<00:53,  2.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 2599 loss tensor(0.2251, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2732/2732 [20:03<00:00,  2.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 step 2731 trainLoss: 0.01740461771988677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 200/2732 [01:19<17:11,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 199 loss tensor(0.1657, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 400/2732 [02:38<15:50,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 399 loss tensor(0.2444, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 600/2732 [03:58<14:29,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 599 loss tensor(0.1325, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 799/2732 [05:11<11:43,  2.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 799 loss tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:43<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5 step 799 acc  0.6738653001464129\n",
      "Update Max eval acc 0.6738653001464129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1000/2732 [07:11<11:45,  2.45it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 999 loss tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1200/2732 [08:30<10:18,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 1199 loss tensor(0.0572, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1400/2732 [09:50<08:57,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 1399 loss tensor(0.1310, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1599/2732 [11:09<07:30,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 1599 loss tensor(0.1027, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:46<00:00,  7.29it/s]\n",
      " 59%|█████▊    | 1600/2732 [11:56<4:33:20, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5 step 1599 acc  0.6588579795021962\n",
      "Early Stopping record count 1 / 6 Will stop Max eval acc 0.6738653001464129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1800/2732 [13:15<06:17,  2.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 1799 loss tensor(0.1680, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2000/2732 [14:32<04:32,  2.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 1999 loss tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2200/2732 [15:45<03:16,  2.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 2199 loss tensor(0.1792, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2399/2732 [16:59<02:12,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 2399 loss tensor(0.1139, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:46<00:00,  7.28it/s]\n",
      " 88%|████████▊ | 2400/2732 [17:47<1:20:16, 14.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  5 step 2399 acc  0.6661786237188873\n",
      "Early Stopping record count 2 / 6 Will stop Max eval acc 0.6738653001464129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2600/2732 [19:06<00:53,  2.48it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 2599 loss tensor(0.0721, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2732/2732 [19:58<00:00,  2.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 step 2731 trainLoss: 0.015860981348916305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 200/2732 [01:19<17:10,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 199 loss tensor(0.0806, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 400/2732 [02:38<15:47,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 399 loss tensor(0.0591, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 600/2732 [03:58<14:23,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 599 loss tensor(0.0355, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 799/2732 [05:11<11:39,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 799 loss tensor(0.1063, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:43<00:00,  7.91it/s]\n",
      " 29%|██▉       | 800/2732 [05:55<7:09:37, 13.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6 step 799 acc  0.66398243045388\n",
      "Early Stopping record count 3 / 6 Will stop Max eval acc 0.6738653001464129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1001/2732 [06:56<05:26,  5.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 999 loss tensor(0.1023, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 1200/2732 [08:14<10:23,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 1199 loss tensor(0.1407, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 1400/2732 [09:33<09:00,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 1399 loss tensor(0.0472, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 1599/2732 [10:52<07:28,  2.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 1599 loss tensor(0.0834, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:46<00:00,  7.29it/s]\n",
      " 59%|█████▊    | 1600/2732 [11:40<4:33:24, 14.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6 step 1599 acc  0.6387262079062958\n",
      "Early Stopping record count 4 / 6 Will stop Max eval acc 0.6738653001464129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 1800/2732 [12:59<06:17,  2.47it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 1799 loss tensor(0.0777, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 2000/2732 [14:18<04:55,  2.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 1999 loss tensor(0.1288, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 2200/2732 [15:32<03:17,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 2199 loss tensor(0.0690, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 2399/2732 [16:45<02:00,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 2399 loss tensor(0.1775, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:45<00:00,  7.54it/s]\n",
      " 88%|████████▊ | 2400/2732 [17:30<1:17:26, 14.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  6 step 2399 acc  0.6522693997071742\n",
      "Early Stopping record count 5 / 6 Will stop Max eval acc 0.6738653001464129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2600/2732 [18:50<00:53,  2.46it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 2599 loss tensor(0.1045, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2732/2732 [19:42<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 step 2731 trainLoss: 0.014193942300119848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 200/2732 [01:19<17:11,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 step 199 loss tensor(0.0582, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 400/2732 [02:38<15:46,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 step 399 loss tensor(0.0970, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 600/2732 [03:58<14:27,  2.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 step 599 loss tensor(0.0889, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 799/2732 [05:15<11:40,  2.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 step 799 loss tensor(0.0443, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 342/342 [00:43<00:00,  7.89it/s]\n",
      " 29%|██▉       | 799/2732 [05:59<14:28,  2.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  7 step 799 acc  0.6500732064421669\n",
      "Early Stopping:Epoch 7  Step 799 Eval_acc 0.6500732064421669\n",
      "epoch 7 step 799 trainLoss: 0.0035291198991394346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('CodeBERTsaved_models/tokenizer_config.json',\n",
       " 'CodeBERTsaved_models/special_tokens_map.json',\n",
       " 'CodeBERTsaved_models/vocab.json',\n",
       " 'CodeBERTsaved_models/merges.txt',\n",
       " 'CodeBERTsaved_models/added_tokens.json')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "max_eval_acc = 0\n",
    "iter_to_accumlate = 4\n",
    "epochloss = []\n",
    "trainlogdf = pd.DataFrame(columns=[\"step\",\"trainloss\",\"validloss\",\"acc\",\"f1-score\"])\n",
    "rowindex = 0\n",
    "eval_no_progress_count = 0\n",
    "early_stopping = 6\n",
    "early_stopping_flag = False\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    allloss = 0\n",
    "    for step,batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch.to(device)\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss/iter_to_accumlate\n",
    "        loss.backward()\n",
    "        allloss += loss.item()\n",
    "        trainlogdf.loc[rowindex] = [rowindex,loss.item(),None,None,None]\n",
    "        rowindex += 1\n",
    "        epochloss.append(loss.item())\n",
    "        if (step+1)%iter_to_accumlate==0:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        if (step+1)%(50*iter_to_accumlate) == 0:\n",
    "            print(\"epoch\",epoch,\"step\",step,\"loss\",loss,sep=\" \")\n",
    "        \n",
    "        if (step+1)%800 == 0:\n",
    "            count = 0\n",
    "            model.eval()\n",
    "            validloss = 0\n",
    "            preds = []\n",
    "            labels = []\n",
    "            for evalstep,batch in enumerate(tqdm(eval_dataloader)):\n",
    "                labels += batch['labels'].cpu()\n",
    "                batch.to(device)\n",
    "                with torch.no_grad():\n",
    "                    output = model(**batch)\n",
    "                validloss += output.loss.item()\n",
    "                pred = torch.argmax(F.softmax(output.logits.cpu(),dim=1),dim=1)\n",
    "                preds += pred\n",
    "                count += int(sum(batch['labels'].cpu() == pred))\n",
    "            model.train()\n",
    "            eval_acc = count/2732\n",
    "            trainlogdf.loc[rowindex-1,\"validloss\"] = validloss/2732\n",
    "            trainlogdf.loc[rowindex-1,\"acc\"] = eval_acc\n",
    "            trainlogdf.loc[rowindex-1,\"f1-score\"] = f1_score(np.array(labels),np.array(preds),average=\"macro\")\n",
    "            print(\"epoch \",epoch,\"step\",step,\"acc \",eval_acc)\n",
    "            if eval_acc < max_eval_acc:\n",
    "                eval_no_progress_count += 1\n",
    "                if eval_no_progress_count >=early_stopping:\n",
    "                    print(\"Early Stopping:Epoch\",epoch,\" Step\",step,\"Eval_acc\",eval_acc,sep=\" \")\n",
    "                    early_stopping_flag = True\n",
    "                    break\n",
    "                else:\n",
    "                    print(\"Early Stopping record count\",eval_no_progress_count,\"/\",early_stopping,\"Will stop\",\"Max eval acc\",max_eval_acc,sep=\" \")\n",
    "            if eval_acc > max_eval_acc:\n",
    "                max_eval_acc = eval_acc\n",
    "                print(\"Update Max eval acc\",max_eval_acc)\n",
    "                eval_no_progress_count = 0\n",
    "                model.save_pretrained(\"CodeBERTsaved_models\")\n",
    "                torch.save(model.state_dict(),os.path.join(\"checkpoint\",\"model.bin\"))\n",
    "                torch.save(optimizer.state_dict(),os.path.join(\"checkpoint\",\"optimizer.bin\"))\n",
    "                torch.save(lr_scheduler.state_dict(),os.path.join(\"checkpoint\",\"lr_scheduler.bin\"))\n",
    "    print(\"epoch\",epoch,\"step\",step,\"trainLoss:\",allloss/(len(train_dataloader)*train_batch_size))\n",
    "    if early_stopping_flag:\n",
    "        break\n",
    "trainlogdf.to_csv(\"trainlog.csv\")\n",
    "tokenizer.save_pretrained(\"CodeBERTsaved_models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example time cost:  0.01 min\n",
      "ALL examples time cost:  0.01 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  1\n",
      "Example time cost:  0.0 min\n",
      "ALL examples time cost:  0.01 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  2\n",
      "Example time cost:  0.0 min\n",
      "ALL examples time cost:  0.01 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  3\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m195\u001b[0m in \u001b[92m<module>\u001b[0m                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m193 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m195 \u001b[2m│   \u001b[0mmain()                                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m145\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   \u001b[0mcode = example[\u001b[33m'\u001b[0m\u001b[33mtext\u001b[0m\u001b[33m'\u001b[0m]                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   \u001b[0mtrue_label = example[\u001b[33m'\u001b[0m\u001b[33mlabel\u001b[0m\u001b[33m'\u001b[0m]                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   \u001b[0msubs = substs[index]                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m145 \u001b[2m│   │   \u001b[0mcode, prog_length, adv_code, true_label, orig_label, temp_labe \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m146 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m│   │   \u001b[0mgreedy_query_times = classifier.query() - query_times          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattacker.py\u001b[0m:\u001b[94m291\u001b[0m in \u001b[92mgreedy_attack\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m288 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 计算importance_score.\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m291 \u001b[2m│   │   \u001b[0mimportance_score, replace_token_positions, names_positions_dic \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m292 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mwords,                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mvariable_names,        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.classifier)       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattacker.py\u001b[0m:\u001b[94m48\u001b[0m in \u001b[92mget_importance_score\u001b[0m                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   │   \u001b[0mnew_code = \u001b[33m'\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m.join(tokens)                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   │   \u001b[0mnew_example.append(new_code)                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 48 \u001b[2m│   \u001b[0mresults = classifier.predict(new_example)                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 49 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m│   \u001b[0morig_prob = results[\u001b[94m0\u001b[0m][\u001b[33m'\u001b[0m\u001b[33mscore\u001b[0m\u001b[33m'\u001b[0m]                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m43\u001b[0m in \u001b[92mpredict\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.querytimes += \u001b[96mlen\u001b[0m(code)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(code) == \u001b[96mstr\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.querytimes += \u001b[94m1\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 43 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.classifier(code)                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mquery\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.querytimes                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m97\u001b[0m in \u001b[92mcls\u001b[0m                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96minput\u001b[0m = tokenizer(example[i*batchsize:batchsize*(i+\u001b[94m1\u001b[0m)] \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96minput\u001b[0m.to(args.device)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   │   │   │   \u001b[0moutput = model(**\u001b[96minput\u001b[0m)                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   │   │   \u001b[0ms = F.softmax(output.logits.float(),dim=\u001b[94m1\u001b[0m)             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   │   │   \u001b[0ms,l = torch.max(s,dim=\u001b[94m1\u001b[0m)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscore += s                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m1216\u001b[0m in \u001b[92mforward\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1213 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1214 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96msel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1215 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1216 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.roberta(                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1217 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1218 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1219 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_type_ids=token_type_ids,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m845\u001b[0m in \u001b[92mforward\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 842 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# and head_mask is converted to shape [num_hidden_layers x ba\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 843 \u001b[0m\u001b[2m│   │   \u001b[0mhead_mask = \u001b[96mself\u001b[0m.get_head_mask(head_mask, \u001b[96mself\u001b[0m.config.num_hid \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 844 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 845 \u001b[2m│   │   \u001b[0membedding_output = \u001b[96mself\u001b[0m.embeddings(                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 846 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=input_ids,                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 847 \u001b[0m\u001b[2m│   │   │   \u001b[0mposition_ids=position_ids,                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 848 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_type_ids=token_type_ids,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m124\u001b[0m in \u001b[92mforward\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 121 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 122 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m inputs_embeds \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 123 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_embeds = \u001b[96mself\u001b[0m.word_embeddings(input_ids)           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 124 \u001b[2m│   │   \u001b[0mtoken_type_embeddings = \u001b[96mself\u001b[0m.token_type_embeddings(token_type \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 125 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 126 \u001b[0m\u001b[2m│   │   \u001b[0membeddings = inputs_embeds + token_type_embeddings            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.position_embedding_type == \u001b[33m\"\u001b[0m\u001b[33mabsolute\u001b[0m\u001b[33m\"\u001b[0m:                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33msp\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33marse.py\u001b[0m:\u001b[94m162\u001b[0m in \u001b[92mforward\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.weight[\u001b[96mself\u001b[0m.padding_idx].fill_(\u001b[94m0\u001b[0m)                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m162 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.embedding(                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.padding_idx, \u001b[96mself\u001b[0m.max_norm,       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.norm_type, \u001b[96mself\u001b[0m.scale_grad_by_freq, \u001b[96mself\u001b[0m.sparse)      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m2210\u001b[0m in \u001b[92membedding\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2207 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m#   torch.embedding_renorm_\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2208 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# remove once script supports set_grad_enabled\u001b[0m                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2209 \u001b[0m\u001b[2m│   │   \u001b[0m_no_grad_embedding_renorm_(weight, \u001b[96minput\u001b[0m, max_norm, norm_type \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2210 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch.embedding(weight, \u001b[96minput\u001b[0m, padding_idx, scale_grad_by_ \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2211 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2212 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2213 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92membedding_bag\u001b[0m(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m14.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m23.67\u001b[0m \n",
      "GiB total capacity; \u001b[1;36m499.20\u001b[0m MiB already allocated; \u001b[1;36m15.56\u001b[0m MiB free; \u001b[1;36m544.00\u001b[0m MiB \n",
      "reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n",
      "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory \n",
      "Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Example time cost:  0.03 min\n",
      "ALL examples time cost:  0.03 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  1\n",
      "Example time cost:  0.0 min\n",
      "ALL examples time cost:  0.03 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  2\n",
      "Example time cost:  0.0 min\n",
      "ALL examples time cost:  0.03 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  3\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m195\u001b[0m in \u001b[92m<module>\u001b[0m                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m193 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m195 \u001b[2m│   \u001b[0mmain()                                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m145\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   \u001b[0mcode = example[\u001b[33m'\u001b[0m\u001b[33mtext\u001b[0m\u001b[33m'\u001b[0m]                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   \u001b[0mtrue_label = example[\u001b[33m'\u001b[0m\u001b[33mlabel\u001b[0m\u001b[33m'\u001b[0m]                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   \u001b[0msubs = substs[index]                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m145 \u001b[2m│   │   \u001b[0mcode, prog_length, adv_code, true_label, orig_label, temp_labe \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m146 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m│   │   \u001b[0mgreedy_query_times = classifier.query() - query_times          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattacker.py\u001b[0m:\u001b[94m291\u001b[0m in \u001b[92mgreedy_attack\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m288 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 计算importance_score.\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m291 \u001b[2m│   │   \u001b[0mimportance_score, replace_token_positions, names_positions_dic \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m292 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mwords,                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mvariable_names,        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.classifier)       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattacker.py\u001b[0m:\u001b[94m48\u001b[0m in \u001b[92mget_importance_score\u001b[0m                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   │   \u001b[0mnew_code = \u001b[33m'\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m.join(tokens)                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   │   \u001b[0mnew_example.append(new_code)                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 48 \u001b[2m│   \u001b[0mresults = classifier.predict(new_example)                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 49 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m│   \u001b[0morig_prob = results[\u001b[94m0\u001b[0m][\u001b[33m'\u001b[0m\u001b[33mscore\u001b[0m\u001b[33m'\u001b[0m]                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m43\u001b[0m in \u001b[92mpredict\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.querytimes += \u001b[96mlen\u001b[0m(code)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(code) == \u001b[96mstr\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.querytimes += \u001b[94m1\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 43 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.classifier(code)                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mquery\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.querytimes                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m97\u001b[0m in \u001b[92mcls\u001b[0m                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96minput\u001b[0m = tokenizer(example[i*batchsize:batchsize*(i+\u001b[94m1\u001b[0m)] \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96minput\u001b[0m.to(args.device)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   │   │   │   \u001b[0moutput = model(**\u001b[96minput\u001b[0m)                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   │   │   \u001b[0ms = F.softmax(output.logits.float(),dim=\u001b[94m1\u001b[0m)             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   │   │   \u001b[0ms,l = torch.max(s,dim=\u001b[94m1\u001b[0m)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscore += s                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m1216\u001b[0m in \u001b[92mforward\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1213 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1214 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96msel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1215 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1216 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.roberta(                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1217 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1218 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1219 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_type_ids=token_type_ids,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m845\u001b[0m in \u001b[92mforward\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 842 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# and head_mask is converted to shape [num_hidden_layers x ba\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 843 \u001b[0m\u001b[2m│   │   \u001b[0mhead_mask = \u001b[96mself\u001b[0m.get_head_mask(head_mask, \u001b[96mself\u001b[0m.config.num_hid \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 844 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 845 \u001b[2m│   │   \u001b[0membedding_output = \u001b[96mself\u001b[0m.embeddings(                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 846 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=input_ids,                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 847 \u001b[0m\u001b[2m│   │   │   \u001b[0mposition_ids=position_ids,                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 848 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_type_ids=token_type_ids,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m124\u001b[0m in \u001b[92mforward\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 121 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 122 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m inputs_embeds \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 123 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_embeds = \u001b[96mself\u001b[0m.word_embeddings(input_ids)           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 124 \u001b[2m│   │   \u001b[0mtoken_type_embeddings = \u001b[96mself\u001b[0m.token_type_embeddings(token_type \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 125 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 126 \u001b[0m\u001b[2m│   │   \u001b[0membeddings = inputs_embeds + token_type_embeddings            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.position_embedding_type == \u001b[33m\"\u001b[0m\u001b[33mabsolute\u001b[0m\u001b[33m\"\u001b[0m:                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33msp\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33marse.py\u001b[0m:\u001b[94m162\u001b[0m in \u001b[92mforward\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.weight[\u001b[96mself\u001b[0m.padding_idx].fill_(\u001b[94m0\u001b[0m)                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m162 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.embedding(                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.padding_idx, \u001b[96mself\u001b[0m.max_norm,       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.norm_type, \u001b[96mself\u001b[0m.scale_grad_by_freq, \u001b[96mself\u001b[0m.sparse)      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m2210\u001b[0m in \u001b[92membedding\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2207 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m#   torch.embedding_renorm_\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2208 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# remove once script supports set_grad_enabled\u001b[0m                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2209 \u001b[0m\u001b[2m│   │   \u001b[0m_no_grad_embedding_renorm_(weight, \u001b[96minput\u001b[0m, max_norm, norm_type \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2210 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch.embedding(weight, \u001b[96minput\u001b[0m, padding_idx, scale_grad_by_ \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2211 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2212 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2213 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92membedding_bag\u001b[0m(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m14.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m23.67\u001b[0m \n",
      "GiB total capacity; \u001b[1;36m499.20\u001b[0m MiB already allocated; \u001b[1;36m15.50\u001b[0m MiB free; \u001b[1;36m544.00\u001b[0m MiB \n",
      "reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n",
      "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory \n",
      "Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Example time cost:  0.03 min\n",
      "ALL examples time cost:  0.03 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  1\n",
      "Example time cost:  0.0 min\n",
      "ALL examples time cost:  0.03 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  2\n",
      "Example time cost:  0.0 min\n",
      "ALL examples time cost:  0.03 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  3\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m195\u001b[0m in \u001b[92m<module>\u001b[0m                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m193 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m195 \u001b[2m│   \u001b[0mmain()                                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m145\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m142 \u001b[0m\u001b[2m│   │   \u001b[0mcode = example[\u001b[33m'\u001b[0m\u001b[33mtext\u001b[0m\u001b[33m'\u001b[0m]                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m143 \u001b[0m\u001b[2m│   │   \u001b[0mtrue_label = example[\u001b[33m'\u001b[0m\u001b[33mlabel\u001b[0m\u001b[33m'\u001b[0m]                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m144 \u001b[0m\u001b[2m│   │   \u001b[0msubs = substs[index]                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m145 \u001b[2m│   │   \u001b[0mcode, prog_length, adv_code, true_label, orig_label, temp_labe \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m146 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m147 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m148 \u001b[0m\u001b[2m│   │   \u001b[0mgreedy_query_times = classifier.query() - query_times          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattacker.py\u001b[0m:\u001b[94m291\u001b[0m in \u001b[92mgreedy_attack\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m288 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m289 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# 计算importance_score.\u001b[0m                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m290 \u001b[0m\u001b[2m│   │   \u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m291 \u001b[2m│   │   \u001b[0mimportance_score, replace_token_positions, names_positions_dic \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m292 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mwords,                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m293 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0mvariable_names,        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m294 \u001b[0m\u001b[2m│   │   │   │   │   │   │   │   │   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.classifier)       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattacker.py\u001b[0m:\u001b[94m48\u001b[0m in \u001b[92mget_importance_score\u001b[0m                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   │   \u001b[0mnew_code = \u001b[33m'\u001b[0m\u001b[33m \u001b[0m\u001b[33m'\u001b[0m.join(tokens)                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   │   \u001b[0mnew_example.append(new_code)                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 47 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 48 \u001b[2m│   \u001b[0mresults = classifier.predict(new_example)                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 49 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 50 \u001b[0m\u001b[2m│   \u001b[0morig_prob = results[\u001b[94m0\u001b[0m][\u001b[33m'\u001b[0m\u001b[33mscore\u001b[0m\u001b[33m'\u001b[0m]                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 51 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m43\u001b[0m in \u001b[92mpredict\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.querytimes += \u001b[96mlen\u001b[0m(code)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(code) == \u001b[96mstr\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.querytimes += \u001b[94m1\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 43 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.classifier(code)                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mquery\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.querytimes                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m97\u001b[0m in \u001b[92mcls\u001b[0m                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96minput\u001b[0m = tokenizer(example[i*batchsize:batchsize*(i+\u001b[94m1\u001b[0m)] \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96minput\u001b[0m.to(args.device)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   │   │   │   \u001b[0moutput = model(**\u001b[96minput\u001b[0m)                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   │   │   \u001b[0ms = F.softmax(output.logits.float(),dim=\u001b[94m1\u001b[0m)             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   │   │   \u001b[0ms,l = torch.max(s,dim=\u001b[94m1\u001b[0m)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscore += s                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m1216\u001b[0m in \u001b[92mforward\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1213 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1214 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96msel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1215 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1216 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.roberta(                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1217 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1218 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1219 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_type_ids=token_type_ids,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m845\u001b[0m in \u001b[92mforward\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 842 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# and head_mask is converted to shape [num_hidden_layers x ba\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 843 \u001b[0m\u001b[2m│   │   \u001b[0mhead_mask = \u001b[96mself\u001b[0m.get_head_mask(head_mask, \u001b[96mself\u001b[0m.config.num_hid \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 844 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 845 \u001b[2m│   │   \u001b[0membedding_output = \u001b[96mself\u001b[0m.embeddings(                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 846 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=input_ids,                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 847 \u001b[0m\u001b[2m│   │   │   \u001b[0mposition_ids=position_ids,                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 848 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_type_ids=token_type_ids,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m124\u001b[0m in \u001b[92mforward\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 121 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 122 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m inputs_embeds \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 123 \u001b[0m\u001b[2m│   │   │   \u001b[0minputs_embeds = \u001b[96mself\u001b[0m.word_embeddings(input_ids)           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 124 \u001b[2m│   │   \u001b[0mtoken_type_embeddings = \u001b[96mself\u001b[0m.token_type_embeddings(token_type \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 125 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 126 \u001b[0m\u001b[2m│   │   \u001b[0membeddings = inputs_embeds + token_type_embeddings            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 127 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.position_embedding_type == \u001b[33m\"\u001b[0m\u001b[33mabsolute\u001b[0m\u001b[33m\"\u001b[0m:                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33msp\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33marse.py\u001b[0m:\u001b[94m162\u001b[0m in \u001b[92mforward\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.weight[\u001b[96mself\u001b[0m.padding_idx].fill_(\u001b[94m0\u001b[0m)                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m162 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.embedding(                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.padding_idx, \u001b[96mself\u001b[0m.max_norm,       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.norm_type, \u001b[96mself\u001b[0m.scale_grad_by_freq, \u001b[96mself\u001b[0m.sparse)      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m2210\u001b[0m in \u001b[92membedding\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2207 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m#   torch.embedding_renorm_\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2208 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# remove once script supports set_grad_enabled\u001b[0m                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2209 \u001b[0m\u001b[2m│   │   \u001b[0m_no_grad_embedding_renorm_(weight, \u001b[96minput\u001b[0m, max_norm, norm_type \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2210 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch.embedding(weight, \u001b[96minput\u001b[0m, padding_idx, scale_grad_by_ \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2211 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2212 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2213 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92membedding_bag\u001b[0m(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m14.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m23.67\u001b[0m \n",
      "GiB total capacity; \u001b[1;36m499.20\u001b[0m MiB already allocated; \u001b[1;36m15.44\u001b[0m MiB free; \u001b[1;36m544.00\u001b[0m MiB \n",
      "reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n",
      "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory \n",
      "Management and PYTORCH_CUDA_ALLOC_CONF\n",
      "Example time cost:  0.03 min\n",
      "ALL examples time cost:  0.03 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  1\n",
      "Example time cost:  0.0 min\n",
      "ALL examples time cost:  0.03 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  2\n",
      "Example time cost:  0.0 min\n",
      "ALL examples time cost:  0.03 min\n",
      "Query times in this attack:  1\n",
      "Greedy query times: 1\n",
      "Ga query times: 0\n",
      "All Query times:  3\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m195\u001b[0m in \u001b[92m<module>\u001b[0m                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m192 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m193 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m194 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m195 \u001b[2m│   \u001b[0mmain()                                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m196 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m155\u001b[0m in \u001b[92mmain\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m152 \u001b[0m\u001b[2m│   │   \u001b[0mganb_changed_pos = \u001b[94m0\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m153 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m is_success == -\u001b[94m1\u001b[0m \u001b[95mand\u001b[0m args.use_ga:                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m154 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# 如果不成功，则使用gi_attack\u001b[0m                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m155 \u001b[2m│   │   │   \u001b[0mcode, prog_length, adv_code, true_label, orig_label, temp_ \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   │   \u001b[0mattack_type = \u001b[33m\"\u001b[0m\u001b[33mGA\u001b[0m\u001b[33m\"\u001b[0m                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   │   \u001b[0mga_query_times = classifier.query() - greedy_query_times - \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m158 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattacker.py\u001b[0m:\u001b[94m158\u001b[0m in \u001b[92mga_attack\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m155 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[2m# 并没有生成新的mutants，直接跳去下一个token\u001b[0m       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m156 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mcontinue\u001b[0m                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m157 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m158 \u001b[2m│   │   │   │   \u001b[0mresults = \u001b[96mself\u001b[0m.classifier.predict(replace_examples)    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m_the_best_candidate = -\u001b[94m1\u001b[0m                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mfor\u001b[0m index, oneresult \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(results):            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m43\u001b[0m in \u001b[92mpredict\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 40 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.querytimes += \u001b[96mlen\u001b[0m(code)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 41 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melif\u001b[0m \u001b[96mtype\u001b[0m(code) == \u001b[96mstr\u001b[0m:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 42 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.querytimes += \u001b[94m1\u001b[0m                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 43 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.classifier(code)                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 44 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 45 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mquery\u001b[0m(\u001b[96mself\u001b[0m):                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 46 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m.querytimes                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/desktop/neutral-attack-for-pretrained-models/CodeBERT/Defect-detec\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33mtion/code/\u001b[0m\u001b[1;33mattack.py\u001b[0m:\u001b[94m97\u001b[0m in \u001b[92mcls\u001b[0m                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 94 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96minput\u001b[0m = tokenizer(example[i*batchsize:batchsize*(i+\u001b[94m1\u001b[0m)] \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 95 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96minput\u001b[0m.to(args.device)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 96 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 97 \u001b[2m│   │   │   │   │   \u001b[0moutput = model(**\u001b[96minput\u001b[0m)                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 98 \u001b[0m\u001b[2m│   │   │   │   \u001b[0ms = F.softmax(output.logits.float(),dim=\u001b[94m1\u001b[0m)             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 99 \u001b[0m\u001b[2m│   │   │   │   \u001b[0ms,l = torch.max(s,dim=\u001b[94m1\u001b[0m)                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m100 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mscore += s                                             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m1216\u001b[0m in \u001b[92mforward\u001b[0m                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1213 \u001b[0m\u001b[2;33m│   │   \u001b[0m\u001b[33m\"\"\"\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1214 \u001b[0m\u001b[2m│   │   \u001b[0mreturn_dict = return_dict \u001b[94mif\u001b[0m return_dict \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[94melse\u001b[0m \u001b[96msel\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1215 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1216 \u001b[2m│   │   \u001b[0moutputs = \u001b[96mself\u001b[0m.roberta(                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1217 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1218 \u001b[0m\u001b[2m│   │   │   \u001b[0mattention_mask=attention_mask,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1219 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_type_ids=token_type_ids,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m845\u001b[0m in \u001b[92mforward\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 842 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# and head_mask is converted to shape [num_hidden_layers x ba\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 843 \u001b[0m\u001b[2m│   │   \u001b[0mhead_mask = \u001b[96mself\u001b[0m.get_head_mask(head_mask, \u001b[96mself\u001b[0m.config.num_hid \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 844 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 845 \u001b[2m│   │   \u001b[0membedding_output = \u001b[96mself\u001b[0m.embeddings(                           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 846 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_ids=input_ids,                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 847 \u001b[0m\u001b[2m│   │   │   \u001b[0mposition_ids=position_ids,                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 848 \u001b[0m\u001b[2m│   │   │   \u001b[0mtoken_type_ids=token_type_ids,                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/transformers/models\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/roberta/\u001b[0m\u001b[1;33mmodeling_roberta.py\u001b[0m:\u001b[94m123\u001b[0m in \u001b[92mforward\u001b[0m                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 120 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mtoken_type_ids = torch.zeros(input_shape, dtype=torch \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 121 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 122 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m inputs_embeds \u001b[95mis\u001b[0m \u001b[94mNone\u001b[0m:                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 123 \u001b[2m│   │   │   \u001b[0minputs_embeds = \u001b[96mself\u001b[0m.word_embeddings(input_ids)           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 124 \u001b[0m\u001b[2m│   │   \u001b[0mtoken_type_embeddings = \u001b[96mself\u001b[0m.token_type_embeddings(token_type \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 125 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 126 \u001b[0m\u001b[2m│   │   \u001b[0membeddings = inputs_embeds + token_type_embeddings            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmo\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mdule.py\u001b[0m:\u001b[94m1501\u001b[0m in \u001b[92m_call_impl\u001b[0m                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1498 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[95mnot\u001b[0m (\u001b[96mself\u001b[0m._backward_hooks \u001b[95mor\u001b[0m \u001b[96mself\u001b[0m._backward_pre_hooks \u001b[95mor\u001b[0m \u001b[96ms\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1499 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_backward_pre_hooks \u001b[95mor\u001b[0m _global_backward_hoo \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1500 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[95mor\u001b[0m _global_forward_hooks \u001b[95mor\u001b[0m _global_forward_pre_hooks \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1501 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m forward_call(*args, **kwargs)                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1502 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Do not call functions when jit is used\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1503 \u001b[0m\u001b[2m│   │   \u001b[0mfull_backward_hooks, non_full_backward_hooks = [], []         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1504 \u001b[0m\u001b[2m│   │   \u001b[0mbackward_pre_hooks = []                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33msp\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33marse.py\u001b[0m:\u001b[94m162\u001b[0m in \u001b[92mforward\u001b[0m                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m159 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[96mself\u001b[0m.weight[\u001b[96mself\u001b[0m.padding_idx].fill_(\u001b[94m0\u001b[0m)                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m160 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m161 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mforward\u001b[0m(\u001b[96mself\u001b[0m, \u001b[96minput\u001b[0m: Tensor) -> Tensor:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m162 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m F.embedding(                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m163 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96minput\u001b[0m, \u001b[96mself\u001b[0m.weight, \u001b[96mself\u001b[0m.padding_idx, \u001b[96mself\u001b[0m.max_norm,       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m164 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[96mself\u001b[0m.norm_type, \u001b[96mself\u001b[0m.scale_grad_by_freq, \u001b[96mself\u001b[0m.sparse)      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m165 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/ljc/anaconda3/envs/adv/lib/python3.8/site-packages/torch/nn/\u001b[0m\u001b[1;33mfunctional\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33m.py\u001b[0m:\u001b[94m2210\u001b[0m in \u001b[92membedding\u001b[0m                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2207 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m#   torch.embedding_renorm_\u001b[0m                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2208 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# remove once script supports set_grad_enabled\u001b[0m                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2209 \u001b[0m\u001b[2m│   │   \u001b[0m_no_grad_embedding_renorm_(weight, \u001b[96minput\u001b[0m, max_norm, norm_type \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2210 \u001b[2m│   \u001b[0m\u001b[94mreturn\u001b[0m torch.embedding(weight, \u001b[96minput\u001b[0m, padding_idx, scale_grad_by_ \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2211 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2212 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2213 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92membedding_bag\u001b[0m(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m48.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m23.67\u001b[0m \n",
      "GiB total capacity; \u001b[1;36m485.48\u001b[0m MiB already allocated; \u001b[1;36m29.38\u001b[0m MiB free; \u001b[1;36m530.00\u001b[0m MiB \n",
      "reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated memory try \n",
      "setting max_split_size_mb to avoid fragmentation.  See documentation for Memory \n",
      "Management and PYTORCH_CUDA_ALLOC_CONF\n"
     ]
    }
   ],
   "source": [
    "!source attack.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
